{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create by: Joelson Antônio dos Santos in December-16-2018.\n",
    "# This implementation follows a mixture of two main bibliographic references (presented below) \n",
    "\n",
    "# [ref 1] - ESTER, M.; KRIEGEL, H.-P.; SANDER, J.; XU, X. A density-based algorithm for discovering\n",
    "# clusters a density-based algorithm for discovering clusters in large spatial databases with noise.\n",
    "# In: Proceedings of the Second International Conference on Knowledge Discovery and Data\n",
    "# Mining. AAAI Press, 1996. (KDD’96), p. 226–231. Available in: <http://dl.acm.org/citation.\n",
    "# cfm?id=3001460.3001507>.\n",
    "\n",
    "#[ref 2] - CAMPELLO, R. J. G. B.; MOULAVI, D.; SANDER, J. Density-based clustering based on\n",
    "# hierarchical density estimates. In: PEI, J.; TSENG, V. S.; CAO, L.; MOTODA, H.; XU, G. (Ed.).\n",
    "# Advances in Knowledge Discovery and Data Mining. Berlin, Heidelberg: Springer Berlin\n",
    "# Heidelberg, 2013. p. 160–172. ISBN 978-3-642-37456-2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import deque\n",
    "from scipy.spatial import distance\n",
    "from sklearn.datasets import load_iris # just for tests\n",
    "\n",
    "class DBSCAN:\n",
    "    def __init__(self, mpts, distanceFunction):\n",
    "        self.setMpts(mpts)\n",
    "        self.setDistanceFunction(distanceFunction)\n",
    "        self.setLabels([])\n",
    "    \n",
    "    def setMpts(self, mpts):\n",
    "        self.mpts = mpts\n",
    "    def setDistanceFunction(self, distanceFunction):\n",
    "        self.distanceFunction = distanceFunction\n",
    "    def setLabels(self, labels):\n",
    "        self.labels = labels\n",
    "    def getMpts(self):\n",
    "        return self.mpts\n",
    "    def getDistanceFunction(self):\n",
    "        return self.distanceFunction\n",
    "    def getLabels(self):\n",
    "        return self.labels\n",
    "        \n",
    "    # some metric (dis-similarities) provided by scipy library (package)\n",
    "    def metric(self, p1, p2):\n",
    "        if self.distanceFunction == \"euclidean\":\n",
    "            return distance.euclidean(p1, p2)\n",
    "        elif self.distanceFunction == \"manhattan\":\n",
    "            return distance.cityblock(p1, p2)\n",
    "        elif self.distanceFunction == \"cosine\":\n",
    "            return distance.cosine(p1, p2)\n",
    "        else:\n",
    "            return distance.euclidean(p1, p2) # default\n",
    "    \n",
    "    # Heuristic method (k-NN)\n",
    "    def epsEstimator(self, dataset):\n",
    "        rows = len(dataset) - 1\n",
    "        maxNNPoints = np.zeros(rows)\n",
    "        for point in range(0, rows): #[improvement] select sample points, not all.\n",
    "            kNNDistances = np.zeros(self.mpts)\n",
    "            for i in range(0, self.mpts - 1):\n",
    "                kNNDistances[i] = sys.float_info.max\n",
    "            for neighbor in range(0, rows):\n",
    "                if point == neighbor:\n",
    "                    continue\n",
    "                # compute distance\n",
    "                distance = self.metric(dataset[point,], dataset[neighbor,]) \n",
    "                shiftLeft = len(kNNDistances) - 1\n",
    "                while shiftLeft > 0 and kNNDistances[shiftLeft] > distance:\n",
    "                    shiftLeft = shiftLeft - 1\n",
    "                if shiftLeft == 0 and kNNDistances[shiftLeft] > distance:\n",
    "                    for i in range(len(kNNDistances) - 1, 0, -1):\n",
    "                        kNNDistances[i] = kNNDistances[i - 1]\n",
    "                    kNNDistances[0] = distance\n",
    "                elif shiftLeft == 0 and kNNDistances[shiftLeft] <= distance:\n",
    "                    for i in range(len(kNNDistances) - 1, 1, -1):\n",
    "                        kNNDistances[i] = kNNDistances[i - 1]\n",
    "                    kNNDistances[1] = distance\n",
    "                else:\n",
    "                    for i in range(len(kNNDistances) - 1, shiftLeft, -1):\n",
    "                        kNNDistances[i] = kNNDistances[i - 1]\n",
    "                    kNNDistances[shiftLeft] = distance\n",
    "            maxNNPoints[point] = kNNDistances[len(kNNDistances) - 1]\n",
    "        return np.median(np.sort(maxNNPoints, kind='quicksort'))\n",
    "     \n",
    "    def fit(self, dataset):\n",
    "        # retrieve core points\n",
    "        rows = len(dataset) - 1\n",
    "        eps = self.epsEstimator(dataset)\n",
    "        # creating an empty adjacent list (graph representation)\n",
    "        adjacentList = dict()\n",
    "        for vertex in range(0, rows):\n",
    "            adjacentList[vertex] = []\n",
    "        for point in range(0, rows):\n",
    "            for neighbor in range(point+1, rows):\n",
    "                if point == neighbor:\n",
    "                    continue\n",
    "                # compute distance\n",
    "                distance = self.metric(dataset[point,], dataset[neighbor,])\n",
    "                if distance <= eps:\n",
    "                    adjacentList[point].append(neighbor)\n",
    "                    adjacentList[neighbor].append(point)\n",
    "        # determining all points as noise, initially\n",
    "        self.labels = np.zeros(rows)\n",
    "        # BFS on each vertex \n",
    "        visitedVertice = np.zeros(rows)\n",
    "        nextClusterLabel = 2\n",
    "        for vertex in range(0, rows):\n",
    "            queue = deque([vertex])\n",
    "            component = [vertex]\n",
    "            if visitedVertice[vertex] == 0:\n",
    "                visitedVertice[vertex] = 1\n",
    "            else:\n",
    "                continue\n",
    "            while len(queue) > 0:\n",
    "                root = queue.pop()\n",
    "                for adj in adjacentList[root]:\n",
    "                    if visitedVertice[adj] == 0:\n",
    "                        visitedVertice[adj] = 1\n",
    "                        component.append(adj)\n",
    "            if len(component) >= self.mpts:\n",
    "                self.labels[component] = nextClusterLabel\n",
    "                nextClusterLabel = nextClusterLabel + 1\n",
    "            component.clear() # remove all elements \n",
    "\n",
    "\n",
    "# test method (can pass dataset[array numpy] or file name as argument)           \n",
    "def runner(mpts, distanceFunction):\n",
    "    # reading a dataset from file\n",
    "    #dataset = np.loadtxt(\"iris.txt\", dtype='float', delimiter=',')\n",
    "    # OR loading some one from a library\n",
    "    dataset = load_iris()\n",
    "    model = DBSCAN(mpts, distanceFunction)\n",
    "    model.fit(dataset['data'])\n",
    "    # label clusters\n",
    "    print(\"DBSCAN using\", model.getDistanceFunction(), \"distance: \", model.getLabels())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN using euclidean distance:  [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 3. 3. 3. 4. 3. 3. 3. 4. 3. 4. 4. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 3. 3.\n",
      " 3. 3. 4. 3. 5. 3. 3. 3. 3. 5. 4. 3. 3. 5. 3. 3. 3. 3. 3. 3. 3. 5. 5. 3.\n",
      " 3. 3. 5. 3. 3. 3. 3. 3. 3. 3. 3. 5. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3.]\n",
      "DBSCAN using manhattan distance:  [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 3. 3. 3. 3. 3. 3. 3. 4. 3. 3. 4. 3. 3. 3. 3. 3. 3. 3. 3. 4. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 3. 3.\n",
      " 3. 3. 4. 3. 3. 3. 3. 3. 3. 5. 4. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 5. 5. 3.\n",
      " 3. 3. 5. 3. 3. 3. 3. 3. 3. 3. 3. 5. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3.]\n",
      "DBSCAN using cosine distance:  [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 4. 4. 3. 3. 4. 4. 4. 3. 4. 3. 3. 3. 3. 4. 4. 3. 3. 3. 4. 3.\n",
      " 3. 4. 4. 3. 3. 3. 3. 3. 4. 3. 3. 3. 4. 3. 4. 3. 4. 3. 3. 3. 4. 3. 4. 4.\n",
      " 4. 3. 3. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# How to run it\n",
    "result1 = runner(4, \"euclidean\")\n",
    "result2 = runner(4, \"manhattan\")\n",
    "result3 = runner(4, \"cosine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
